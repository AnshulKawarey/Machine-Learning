{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 5: Assignment - Prepare Titanic Dataset for Modeling\n",
    "\n",
    "**Course**: Machine Learning with Python: From Basics to Applications  \n",
    "**Objective**: Combine preprocessing steps from Days 3 and 4 to fully prepare the Titanic dataset for machine learning modeling.  \n",
    "**Prerequisites**: Basic Python knowledge, familiarity with NumPy, Pandas (Day 2), handling missing values and encoding (Day 3), and train/test split with feature scaling (Day 4).  \n",
    "**Tools**: Pandas, scikit-learn (install with `pip install pandas scikit-learn`).  \n",
    "**Dataset**: Raw Titanic dataset (`titanic.csv`, available from Kaggle or provided).  \n",
    "\n",
    "In this notebook, we will:  \n",
    "1. Load the raw Titanic dataset.  \n",
    "2. Handle missing values (impute `Age` with median, drop rows with missing `Embarked`).  \n",
    "3. Encode categorical variables (`Gender` with `LabelEncoder`, `Embarked` with one-hot encoding).  \n",
    "4. Split data into training (80%) and test (20%) sets.  \n",
    "5. Scale numerical features (`Age`, `Fare`) using `StandardScaler`.  \n",
    "6. Save the preprocessed and split datasets as CSVs.  \n",
    "7. Verify all steps (no missing values, correct encoding, split sizes, and scaling).  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import Libraries\n",
    "\n",
    "Import Pandas for data handling, scikit-learn for encoding, splitting, and scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load the Titanic Dataset\n",
    "\n",
    "Load the raw Titanic dataset and inspect it to identify missing values and data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of raw data:\n",
      "\n",
      "Dataset info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n",
      "\n",
      "Missing values:\n",
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('titanic.csv')\n",
    "\n",
    "# Display first 5 rows\n",
    "print(\"First 5 rows of raw data:\")\n",
    "df.head()\n",
    "\n",
    "# Check data info and missing values\n",
    "print(\"\\nDataset info:\")\n",
    "df.info()\n",
    "\n",
    "print(\"\\nMissing values:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**:  \n",
    "- `df.head()` shows columns like `PassengerId`, `Survived`, `Pclass`, `Gender`, `Age`, `Fare`, `Embarked`, etc.  \n",
    "- `df.info()` shows data types (e.g., `Age` as float, `Gender` as object).  \n",
    "- `df.isnull().sum()` likely shows ~177 missing values for `Age`, ~2 for `Embarked`, and many for `Cabin`.  \n",
    "\n",
    "**Note**: We’ll focus on `Age` and `Embarked`; `Cabin` has too many missing values and will be ignored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Handle Missing Values\n",
    "\n",
    "Impute missing `Age` values with the median to preserve data. Drop rows with missing `Embarked` values since they are few."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values after handling:\n",
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age              0\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Impute missing Age with median\n",
    "df['Age'] = df['Age'].fillna(df['Age'].median())\n",
    "\n",
    "# Drop rows with missing Embarked\n",
    "df.dropna(subset=['Embarked'], inplace=True)\n",
    "\n",
    "# Verify missing values\n",
    "print(\"Missing values after handling:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**:  \n",
    "- No missing values for `Age` or `Embarked`.  \n",
    "- `Cabin` may still have missing values, but we’re ignoring it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Encode Categorical Variables\n",
    "\n",
    "Encode `Gender` using `LabelEncoder` (male=0, female=1). Encode `Embarked` using one-hot encoding with `pd.get_dummies` and drop the first dummy column to avoid multicollinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 5 rows after encoding:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name  Sex   Age  SibSp  Parch  \\\n",
       "0                            Braund, Mr. Owen Harris    1  22.0      1      0   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...    0  38.0      1      0   \n",
       "2                             Heikkinen, Miss. Laina    0  26.0      0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)    0  35.0      1      0   \n",
       "4                           Allen, Mr. William Henry    1  35.0      0      0   \n",
       "\n",
       "             Ticket     Fare Cabin  Embarked_Q  Embarked_S  \n",
       "0         A/5 21171   7.2500   NaN       False        True  \n",
       "1          PC 17599  71.2833   C85       False       False  \n",
       "2  STON/O2. 3101282   7.9250   NaN       False        True  \n",
       "3            113803  53.1000  C123       False        True  \n",
       "4            373450   8.0500   NaN       False        True  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode Gender with LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df['Gender'] = le.fit_transform(df['Gender'])\n",
    "\n",
    "# Encode Embarked with one-hot encoding\n",
    "df = pd.get_dummies(df, columns=['Embarked'], drop_first=True)\n",
    "\n",
    "# Display first 5 rows after encoding\n",
    "print(\"\\nFirst 5 rows after encoding:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**:  \n",
    "- `Gender` is now 0 or 1 (0=male, 1=female).  \n",
    "- `Embarked` is replaced by `Embarked_C` and `Embarked_Q` (binary columns), with `Embarked_S` dropped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Train/Test Split\n",
    "\n",
    "Split the data into 80% training and 20% test sets using `train_test_split`. Set `random_state=42` for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape (X_train, y_train): (711, 12) (711,)\n",
      "Test set shape (X_test, y_test): (178, 12) (178,)\n"
     ]
    }
   ],
   "source": [
    "# Separate features and target\n",
    "X = df.drop('Survived', axis=1)\n",
    "y = df['Survived']\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Verify shapes\n",
    "print(\"Training set shape (X_train, y_train):\", X_train.shape, y_train.shape)\n",
    "print(\"Test set shape (X_test, y_test):\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**:  \n",
    "- `X_train` and `y_train`: ~712 rows (80% of ~889 after dropping rows).  \n",
    "- `X_test` and `y_test`: ~177 rows (20%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Feature Scaling\n",
    "\n",
    "Apply `StandardScaler` to scale numerical features (`Age`, `Fare`). Fit the scaler on the training data and transform both training and test data to avoid data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Age mean after scaling: -1.0618166761534549e-16\n",
      "Training Age std after scaling: 1.0007039775599107\n",
      "Training Fare mean after scaling: 1.99871374334768e-17\n",
      "Training Fare std after scaling: 1.0007039775599105\n",
      "\n",
      "First 5 rows of X_train after scaling:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>709</td>\n",
       "      <td>1</td>\n",
       "      <td>Cleaver, Miss. Alice</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.571868</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113781</td>\n",
       "      <td>2.430597</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>241</td>\n",
       "      <td>3</td>\n",
       "      <td>Zabour, Miss. Thamine</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.115088</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2665</td>\n",
       "      <td>-0.358135</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>383</td>\n",
       "      <td>3</td>\n",
       "      <td>Tikkanen, Mr. Juho</td>\n",
       "      <td>1</td>\n",
       "      <td>0.189432</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O 2. 3101293</td>\n",
       "      <td>-0.490949</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>793</td>\n",
       "      <td>3</td>\n",
       "      <td>Sage, Miss. Stella Anna</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.115088</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>CA. 2343</td>\n",
       "      <td>0.762595</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>684</td>\n",
       "      <td>3</td>\n",
       "      <td>Goodwin, Mr. Charles Edward</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.180908</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>CA 2144</td>\n",
       "      <td>0.301860</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Pclass                         Name  Sex       Age  SibSp  \\\n",
       "708          709       1         Cleaver, Miss. Alice    0 -0.571868      0   \n",
       "240          241       3        Zabour, Miss. Thamine    0 -0.115088      1   \n",
       "382          383       3           Tikkanen, Mr. Juho    1  0.189432      0   \n",
       "792          793       3      Sage, Miss. Stella Anna    0 -0.115088      8   \n",
       "683          684       3  Goodwin, Mr. Charles Edward    1 -1.180908      5   \n",
       "\n",
       "     Parch             Ticket      Fare Cabin  Embarked_Q  Embarked_S  \n",
       "708      0             113781  2.430597   NaN       False        True  \n",
       "240      0               2665 -0.358135   NaN       False       False  \n",
       "382      0  STON/O 2. 3101293 -0.490949   NaN       False        True  \n",
       "792      2           CA. 2343  0.762595   NaN       False        True  \n",
       "683      2            CA 2144  0.301860   NaN       False        True  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform on training data (Age, Fare)\n",
    "X_train[['Age', 'Fare']] = scaler.fit_transform(X_train[['Age', 'Fare']])\n",
    "\n",
    "# Transform test data (using same scaler)\n",
    "X_test[['Age', 'Fare']] = scaler.transform(X_test[['Age', 'Fare']])\n",
    "\n",
    "# Verify scaling (mean ~0, std ~1 for training data)\n",
    "print(\"Training Age mean after scaling:\", X_train['Age'].mean())\n",
    "print(\"Training Age std after scaling:\", X_train['Age'].std())\n",
    "print(\"Training Fare mean after scaling:\", X_train['Fare'].mean())\n",
    "print(\"Training Fare std after scaling:\", X_train['Fare'].std())\n",
    "\n",
    "# Display first few rows of scaled training data\n",
    "print(\"\\nFirst 5 rows of X_train after scaling:\")\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**:  \n",
    "- `Age` and `Fare` in `X_train`: Mean ~0, std ~1.  \n",
    "- `X_test` values are scaled but may have slightly different mean/std (normal, as scaler was fit on training data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Save Datasets\n",
    "\n",
    "Save the preprocessed and split datasets as CSV files for use in Week 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save training and test datasets\n",
    "X_train.to_csv('titanic_X_train_final.csv', index=False)\n",
    "X_test.to_csv('titanic_X_test_final.csv', index=False)\n",
    "y_train.to_csv('titanic_y_train.csv', index=False)\n",
    "y_test.to_csv('titanic_y_test.csv', index=False)\n",
    "\n",
    "print(\"Datasets saved as titanic_X_train_final.csv, titanic_X_test_final.csv, titanic_y_train.csv, titanic_y_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Verification\n",
    "\n",
    "Verify that the datasets are correctly preprocessed, split, and scaled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify saved files\n",
    "print(\"\\nVerify X_train_final.csv:\")\n",
    "print(pd.read_csv('titanic_X_train_final.csv').head())\n",
    "\n",
    "# Confirm no missing values\n",
    "print(\"\\nMissing values in X_train:\", X_train.isnull().sum().sum())\n",
    "print(\"Missing values in X_test:\", X_test.isnull().sum().sum())\n",
    "\n",
    "# Check unique values for Gender\n",
    "print(\"\\nUnique values in Gender (X_train):\", X_train['Gender'].unique())\n",
    "\n",
    "# Check columns for Embarked encoding\n",
    "print(\"\\nColumns in X_train:\", X_train.columns.tolist())\n",
    "\n",
    "# Verify split sizes\n",
    "print(\"\\nTraining set size:\", X_train.shape[0])\n",
    "print(\"Test set size:\", X_test.shape[0])\n",
    "\n",
    "# Verify scaling\n",
    "print(\"\\nTraining Age mean:\", X_train['Age'].mean())\n",
    "print(\"Training Age std:\", X_train['Age'].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**:  \n",
    "- No missing values in `X_train` or `X_test` (except possibly `Cabin`, ignored).  \n",
    "- `Gender` has values [0, 1].  \n",
    "- Columns include `Embarked_C`, `Embarked_Q` (not `Embarked_S`).  \n",
    "- Training set: ~712 rows, test set: ~177 rows.  \n",
    "- `Age` and `Fare` in `X_train`: Mean ~0, std ~1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment\n",
    "\n",
    "1. Run this notebook to preprocess, split, and scale the Titanic dataset.  \n",
    "2. Verify:  \n",
    "   - No missing values for `Age` and `Embarked`.  \n",
    "   - `Gender` is encoded as 0/1, `Embarked` as `Embarked_C`, `Embarked_Q`.  \n",
    "   - Split sizes are 80% training (\\~712 rows), 20% test (\\~177 rows).  \n",
    "   - `Age` and `Fare` in `X_train` have mean ~0 and std ~1.  \n",
    "3. Ensure the saved CSV files (`titanic_X_train_final.csv`, etc.) are created and correct.  \n",
    "4. Submit a screenshot of the notebook output showing the verification steps (missing values, `Gender` unique values, columns, split sizes, and scaling stats).  \n",
    "\n",
    "**Next Steps**: In Week 2, you’ll use these datasets to train machine learning models like linear regression and logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
