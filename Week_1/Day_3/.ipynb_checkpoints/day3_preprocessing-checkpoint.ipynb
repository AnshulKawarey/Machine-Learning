{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Day 3: Data Preprocessing - Missing Values and Encoding\n",
        "\n",
        "**Course**: Machine Learning with Python: From Basics to Applications  \n",
        "**Objective**: Learn to handle missing data and encode categorical variables to prepare datasets for machine learning models.  \n",
        "**Prerequisites**: Basic Python knowledge, familiarity with NumPy and Pandas (from Day 2), and the raw Titanic dataset (`titanic.csv`).  \n",
        "**Tools**: Pandas, scikit-learn (install with `pip install pandas scikit-learn`).  \n",
        "**Dataset**: Titanic dataset (raw, available from Kaggle or provided).  \n",
        "\n",
        "In this notebook, we will:  \n",
        "1. Load the raw Titanic dataset.  \n",
        "2. Check for and handle missing values (impute `Age` with median, drop rows with missing `Embarked`).  \n",
        "3. Encode categorical variables (`Sex` with `LabelEncoder`, `Embarked` with one-hot encoding).  \n",
        "4. Save the preprocessed dataset as a CSV.  \n",
        "5. Verify the preprocessing steps.  \n",
        "\n",
        "Let’s get started!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Import Libraries\n",
        "\n",
        "We need Pandas for data handling and scikit-learn’s `LabelEncoder` for encoding categorical variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Load the Titanic Dataset\n",
        "\n",
        "Load the raw Titanic dataset (`titanic.csv`) and inspect it to understand its structure and identify missing values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv('titanic.csv')\n",
        "\n",
        "# Display first 5 rows\n",
        "print(\"First 5 rows of raw data:\")\n",
        "df.head()\n",
        "\n",
        "# Check data info and missing values\n",
        "print(\"\\nDataset info:\")\n",
        "df.info()\n",
        "\n",
        "print(\"\\nMissing values:\")\n",
        "print(df.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Expected Output**:  \n",
        "- `df.head()` shows columns like `PassengerId`, `Survived`, `Pclass`, `Sex`, `Age`, `Fare`, `Embarked`, etc.  \n",
        "- `df.info()` shows data types (e.g., `Age` as float, `Sex` as object).  \n",
        "- `df.isnull().sum()` likely shows ~177 missing values for `Age`, ~2 for `Embarked`, and many for `Cabin`.  \n",
        "\n",
        "**Note**: We’ll focus on `Age` and `Embarked` for this exercise; `Cabin` has too many missing values and can be ignored."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Handle Missing Values\n",
        "\n",
        "Impute missing `Age` values with the median to preserve data. Drop rows with missing `Embarked` values since they are few."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Impute missing Age with median\n",
        "df['Age'].fillna(df['Age'].median(), inplace=True)\n",
        "\n",
        "# Drop rows with missing Embarked\n",
        "df.dropna(subset=['Embarked'], inplace=True)\n",
        "\n",
        "# Verify missing values\n",
        "print(\"Missing values after handling:\")\n",
        "print(df.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Expected Output**:  \n",
        "- No missing values for `Age` or `Embarked`.  \n",
        "- `Cabin` may still have missing values, but we’re ignoring it for now."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Encode Categorical Variables\n",
        "\n",
        "Encode `Sex` using `LabelEncoder` (male=0, female=1). Encode `Embarked` using one-hot encoding with `pd.get_dummies` and drop the first dummy column to avoid multicollinearity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Encode Sex with LabelEncoder\n",
        "le = LabelEncoder()\n",
        "df['Sex'] = le.fit_transform(df['Sex'])\n",
        "\n",
        "# Encode Embarked with one-hot encoding\n",
        "df = pd.get_dummies(df, columns=['Embarked'], drop_first=True)\n",
        "\n",
        "# Display first 5 rows after encoding\n",
        "print(\"\\nFirst 5 rows after encoding:\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Expected Output**:  \n",
        "- `Sex` is now 0 or 1 (0=male, 1=female).  \n",
        "- `Embarked` is replaced by `Embarked_C` and `Embarked_Q` (binary columns), with `Embarked_S` dropped."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Save Preprocessed Dataset\n",
        "\n",
        "Save the preprocessed dataset as `titanic_preprocessed.csv` for use in future sessions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save preprocessed data\n",
        "df.to_csv('titanic_preprocessed.csv', index=False)\n",
        "\n",
        "print(\"Preprocessed dataset saved as titanic_preprocessed.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Verification\n",
        "\n",
        "Verify that the dataset has no missing values, `Sex` is encoded as 0/1, and `Embarked` is one-hot encoded."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verify saved file\n",
        "print(\"\\nVerify titanic_preprocessed.csv:\")\n",
        "print(pd.read_csv('titanic_preprocessed.csv').head())\n",
        "\n",
        "# Confirm no missing values\n",
        "print(\"\\nMissing values in preprocessed data:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Check unique values for Sex\n",
        "print(\"\\nUnique values in Sex:\", df['Sex'].unique())\n",
        "\n",
        "# Check columns for Embarked encoding\n",
        "print(\"\\nColumns after encoding:\", df.columns.tolist())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Expected Output**:  \n",
        "- No missing values (except possibly `Cabin`, which we’re ignoring).  \n",
        "- `Sex` has values [0, 1].  \n",
        "- Columns include `Embarked_C`, `Embarked_Q` (but not `Embarked_S`)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Assignment\n",
        "\n",
        "1. Run this notebook to preprocess the Titanic dataset.  \n",
        "2. Verify no missing values for `Age` and `Embarked`.  \n",
        "3. Confirm `Sex` is encoded as 0/1 and `Embarked` is one-hot encoded (`Embarked_C`, `Embarked_Q`).  \n",
        "4. Ensure the saved `titanic_preprocessed.csv` contains the expected columns and data.  \n",
        "5. Submit a screenshot of the notebook output showing the verification steps (missing values, unique values for `Sex`, and column names).  \n",
        "\n",
        "**Next Steps**: On Day 4, we’ll split this preprocessed dataset into training and test sets and apply feature scaling."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}